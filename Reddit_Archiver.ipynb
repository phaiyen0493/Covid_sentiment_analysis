{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2494def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name:Yen Pham\n",
    "#CSCE 5290  Project\n",
    "\n",
    "import json\n",
    "import os\n",
    "import praw\n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import timezone\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "SUBREDDIT_POST_LIMIT = 100\n",
    "\n",
    "# Need to register for Reddit developer account and take the API keys\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "user_agent = ''\n",
    "username = ''\n",
    "password = ''\n",
    "\n",
    "#Verify accounts\n",
    "reddit= praw.Reddit(client_id=client_id, client_secret=client_secret,user_agent=user_agent,username=username,password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc04aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "\n",
    "created_times = []\n",
    "authors = []\n",
    "texts = []\n",
    "# Open existing file (if existed) to combine with this scraped data later\n",
    "filename = \"D:\\CSCE5290-Natural Language Processing\\Project\\Reddit_covid_threads.csv\"\n",
    "if path.exists(filename):\n",
    "    df = pd.read_csv(filename, header = 0)\n",
    "    authors = df['User_ID'].to_list()\n",
    "    texts = df['Text'].to_list()\n",
    "    created_times = df['Time_Stamp'].to_list()\n",
    "\n",
    "# Subreddits list\n",
    "hot_subs = []\n",
    "topics = ['Coronavirus','COVID19','COVID19positive','China_Flu','COVID19_support','CoronavirusCanada','LockdownSkepticism','CovIdiots','CoronavirusUK',\n",
    "         'CanadaCoronavirus','CoronavirusDownunder','CoronavirusUS','CoronavirusCirclejerk','covidlonghaulers','FloridaCoronavirus','CoronavirusMichigan',\n",
    "         'CoronavirusGA','CoronaVirusTX','CoronavirusMa','CoronavirusCA','CoronavirusWA','CoronavirusAZ','CoronavirusWI','Coronaviruslouisiana', \n",
    "          'CoronavirusOregon','CoronavirusOklahoma','CoronavirusColorado','CoronavirusUT','coronavirusnewmexico','CovidVaccinated','LockdownCriticalLeft',\n",
    "         'Moronavirus','coronavirusme','CoronavirusIllinois','vaxxhappened','COVIDAteMyFace','nycCoronavirus', 'CoronavirusMN', 'Coronavirus_Ireland',\n",
    "          'Coronavirus_BC','ChurchOfCOVID','Coronavirus_PH','CoronavirusNewYork','CoronavirusFOS','CoronavirusTN']\n",
    "\n",
    "# Get \"hot\" posts from each subreddit\n",
    "for topic in list(set(topics)):\n",
    "    hot_subs.append(reddit.subreddit(topic).hot(limit=SUBREDDIT_POST_LIMIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a623b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data into arrays for each post\n",
    "def get_data(submission, created_times, authors, texts):\n",
    "    '''Creates files out of a set of reddit submissions'''\n",
    "    for post in submission:\n",
    "#         print(post.created_utc)\n",
    "#         print(datetime.datetime(2021,10,20, tzinfo=timezone.utc).replace(tzinfo=timezone.utc).timestamp())\n",
    "#         if (post.created_utc >= 1634774400.0):\n",
    "#             print(\"true\")\n",
    "        created_times.append(post.created_utc)\n",
    "        authors.append(post.author)\n",
    "        texts.append(post.selftext)\n",
    "        for comment in post.comments:\n",
    "            created_times.append(comment.created_utc)\n",
    "            authors.append(comment.author)\n",
    "            texts.append(comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2a1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing post #42.0/45"
     ]
    }
   ],
   "source": [
    "# print(hot_subs)\n",
    "# print(len(texts)) \n",
    "i = 1\n",
    "#record everytime one subreddit is finished scraping\n",
    "for submission in hot_subs:\n",
    "    print(f\"\\rProcessing post #{i}.0/{len(hot_subs)}\", end=\"\")\n",
    "#     print(submission)\n",
    "    try:\n",
    "        get_data(submission, created_times, authors, texts)\n",
    "        i += 1\n",
    "    except:\n",
    "        continue\n",
    "     \n",
    "# for item in created_times:\n",
    "#     item = datetime.fromtimestamp(item, pytz.timezone(\"UTC\"))\n",
    "\n",
    "#put sraped data in dataframe and save into file\n",
    "data = {'Time_Stamp': created_times, 'User_ID': authors, 'Text':texts}\n",
    "df1 = pd.DataFrame(data)\n",
    "df1.drop_duplicates()\n",
    "df1.to_csv(r'D:\\CSCE5290-Natural Language Processing\\Project\\Reddit_covid_threads.csv', index = False) \n",
    "\n",
    "# import pandas as pd\n",
    "# # df = pd.read_csv ('file_name.csv')\n",
    "# # print(df)\n",
    "\n",
    "# from datetime import datetime\n",
    "# import pytz\n",
    "# # print(type(datetime.fromtimestamp(1617452204, pytz.timezone(\"UTC\"))))\n",
    "\n",
    "# from datetime import timezone\n",
    "# import datetime\n",
    "  \n",
    "  \n",
    "# # Getting the current date\n",
    "# # and time\n",
    "# dt = datetime.datetime(2021,10,21, tzinfo=timezone.utc).replace(tzinfo=timezone.utc).timestamp()\n",
    "  \n",
    "# # utc_time = dt.replace(tzinfo=timezone.utc)\n",
    "# # utc_timestamp = utc_time.timestamp()\n",
    "  \n",
    "# print(dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
